# Deep Learning from Scratch — PyTorch

This repo is a personal journey into the **practical implementation** of deep learning using PyTorch built **completely from scratch**, step by step.

After spending time understanding the **mathematics** and **core architectures** behind deep learning  from neural networks to CNNs, RNNs, and LSTMs — I wanted to shift from just *knowing* to actually *building*.

The goal?  
To learn deeply, not just use libraries.  
To be able to debug, optimize, and enhance performance when things go wrong in real-world projects.

---

## 🔍 What You'll Find in This Repo

This is not about using high-level APIs and getting quick results.  
This is about **understanding what happens under the hood**.

### ✅ Notebooks so far:
1. **Tensors Playground**  
   - Explored PyTorch tensors and their operations.
   - Understood how they differ from NumPy and why they're fundamental.

2. **Autograd Basics**  
   - Played with PyTorch's automatic differentiation.
   - Visualized how gradients flow and learned how `.backward()` works.

3. **End-to-End Training Pipeline**  
   - Built a full pipeline: data → preprocessing → training a single-neuron ANN.
   - Wrote a custom model class from scratch.

---

## 🔧 Coming Up / In Progress
- [x] ANN (Artificial Neural Network) from scratch  
- [ ] CNN (Convolutional Neural Network)  
- [ ] RNN (Recurrent Neural Network)  
- [ ] LSTM (Long Short-Term Memory)  
- [ ] Full projects to master PyTorch workflows

---



Feel free to explore, clone, or use the notebooks as inspiration for your own learning.

> No black boxes. Just deep learning, deeply understood.

---

